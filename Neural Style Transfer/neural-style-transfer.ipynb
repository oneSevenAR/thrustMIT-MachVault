{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca8f82d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T05:05:45.745505Z",
     "iopub.status.busy": "2025-04-03T05:05:45.745236Z",
     "iopub.status.idle": "2025-04-03T05:05:53.669211Z",
     "shell.execute_reply": "2025-04-03T05:05:53.668322Z"
    },
    "papermill": {
     "duration": 7.928979,
     "end_time": "2025-04-03T05:05:53.670683",
     "exception": false,
     "start_time": "2025-04-03T05:05:45.741704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image, ImageEnhance\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"GPU Name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "\n",
    "# Clear GPU memory\n",
    "def clear_gpu_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"GPU memory cleared\")\n",
    "\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbeec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T05:05:53.676092Z",
     "iopub.status.busy": "2025-04-03T05:05:53.675728Z",
     "iopub.status.idle": "2025-04-03T05:05:54.015506Z",
     "shell.execute_reply": "2025-04-03T05:05:54.014418Z"
    },
    "papermill": {
     "duration": 0.34385,
     "end_time": "2025-04-03T05:05:54.016939",
     "exception": false,
     "start_time": "2025-04-03T05:05:53.673089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load content and style images with error handling\n",
    "# Update paths for Kaggle (e.g., upload files to /kaggle/input/)\n",
    "try:\n",
    "    content_image = Image.open('/kaggle/input/data123/content_img2.jpeg').convert('RGB')\n",
    "    style_image = Image.open('/kaggle/input/data123/starry_night.jpg').convert('RGB')\n",
    "except FileNotFoundError as e:\n",
    "    raise FileNotFoundError(f\"Image not found: {e}. Upload images to /kaggle/input/\")\n",
    "\n",
    "# Preprocess images\n",
    "content_tensor = transform(content_image).unsqueeze(0).to(device)\n",
    "style_tensor = transform(style_image).unsqueeze(0).to(device)\n",
    "\n",
    "# Verify shapes\n",
    "print(f\"Content Tensor Shape: {content_tensor.shape}\")  # Should be [1, 3, 512, 512]\n",
    "print(f\"Style Tensor Shape: {style_tensor.shape}\")    # Should be [1, 3, 512, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670e1d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T05:05:54.022209Z",
     "iopub.status.busy": "2025-04-03T05:05:54.021938Z",
     "iopub.status.idle": "2025-04-03T05:05:58.411505Z",
     "shell.execute_reply": "2025-04-03T05:05:58.410721Z"
    },
    "papermill": {
     "duration": 4.39373,
     "end_time": "2025-04-03T05:05:58.412987",
     "exception": false,
     "start_time": "2025-04-03T05:05:54.019257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pretrained VGG-19\n",
    "vgg = models.vgg19(pretrained=True).features.to(device).eval()\n",
    "\n",
    "# Layers for content and style\n",
    "content_layers = ['conv_4_2']  # Layer 21 in VGG-19\n",
    "style_layers = ['conv_1_1', 'conv_2_1', 'conv_3_1', 'conv_4_1', 'conv_5_1']  # Layers 0, 5, 10, 19, 28\n",
    "\n",
    "# Mapping layer names to indices\n",
    "layer_names = {\n",
    "    '0': 'conv_1_1', '5': 'conv_2_1', '10': 'conv_3_1', \n",
    "    '19': 'conv_4_1', '21': 'conv_4_2', '28': 'conv_5_1'\n",
    "}\n",
    "\n",
    "# Feature extractor\n",
    "class VGGFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGFeatureExtractor, self).__init__()\n",
    "        self.vgg = vgg\n",
    "        self.content_layers = content_layers\n",
    "        self.style_layers = style_layers\n",
    "    \n",
    "    def forward(self, x):\n",
    "        content_features = []\n",
    "        style_features = []\n",
    "        for i, layer in enumerate(self.vgg):\n",
    "            x = layer(x)\n",
    "            name = layer_names.get(str(i))\n",
    "            if name in self.content_layers:\n",
    "                content_features.append(x)\n",
    "            if name in self.style_layers:\n",
    "                style_features.append(x)\n",
    "        return content_features, style_features\n",
    "\n",
    "feature_extractor = VGGFeatureExtractor().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4617cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T05:05:58.421582Z",
     "iopub.status.busy": "2025-04-03T05:05:58.421320Z",
     "iopub.status.idle": "2025-04-03T05:05:58.426797Z",
     "shell.execute_reply": "2025-04-03T05:05:58.426106Z"
    },
    "papermill": {
     "duration": 0.010984,
     "end_time": "2025-04-03T05:05:58.428085",
     "exception": false,
     "start_time": "2025-04-03T05:05:58.417101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def content_loss(target, content):\n",
    "    return nn.MSELoss()(target, content)\n",
    "\n",
    "def gram_matrix(tensor):\n",
    "    b, c, h, w = tensor.size()\n",
    "    tensor = tensor.view(b * c, h * w)\n",
    "    gram = torch.mm(tensor, tensor.t())\n",
    "    return gram.div(b * c * h * w)\n",
    "\n",
    "def style_loss(target, style):\n",
    "    loss = 0\n",
    "    for t, s in zip(target, style):\n",
    "        t_gram = gram_matrix(t)\n",
    "        s_gram = gram_matrix(s)\n",
    "        layer_loss = nn.MSELoss()(t_gram, s_gram)\n",
    "        loss += layer_loss\n",
    "    return loss\n",
    "\n",
    "def total_variation_loss(image):\n",
    "    return torch.sum(torch.abs(image[:, :, :, :-1] - image[:, :, :, 1:])) + \\\n",
    "           torch.sum(torch.abs(image[:, :, :-1, :] - image[:, :, 1:, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf61ba41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T05:05:58.435764Z",
     "iopub.status.busy": "2025-04-03T05:05:58.435554Z",
     "iopub.status.idle": "2025-04-03T05:05:58.493183Z",
     "shell.execute_reply": "2025-04-03T05:05:58.492572Z"
    },
    "papermill": {
     "duration": 0.062987,
     "end_time": "2025-04-03T05:05:58.494560",
     "exception": false,
     "start_time": "2025-04-03T05:05:58.431573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StyleTransferModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StyleTransferModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),  \n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),  \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
    "        )\n",
    "        for module in self.model:\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(module.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.tanh(self.model(x))\n",
    "\n",
    "# Initialize model\n",
    "model = StyleTransferModel().to(device)\n",
    "optimizer = optim.LBFGS(model.parameters(), lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea24501e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T05:05:58.508204Z",
     "iopub.status.busy": "2025-04-03T05:05:58.507795Z",
     "iopub.status.idle": "2025-04-03T11:19:33.751730Z",
     "shell.execute_reply": "2025-04-03T11:19:33.750804Z"
    },
    "papermill": {
     "duration": 22415.251973,
     "end_time": "2025-04-03T11:19:33.753125",
     "exception": false,
     "start_time": "2025-04-03T05:05:58.501152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 1000\n",
    "content_weight = 5.0\n",
    "style_weight = 5e6\n",
    "tv_weight = 1e-5\n",
    "min_loss_improvement = 1e-4\n",
    "patience = 100\n",
    "\n",
    "# Lists to save losses\n",
    "content_losses = []\n",
    "style_losses = []\n",
    "tv_losses = []\n",
    "total_losses = []\n",
    "\n",
    "# Precompute style and content features\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    _, style_feats = feature_extractor(style_tensor)\n",
    "    content_feats, _ = feature_extractor(content_tensor)\n",
    "\n",
    "# Training with LBFGS\n",
    "model.train()\n",
    "best_loss = float('inf')\n",
    "no_improvement_count = 0\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    stylized_image = model(content_tensor)\n",
    "    stylized_content_feats, stylized_style_feats = feature_extractor(stylized_image)\n",
    "    \n",
    "    # Compute losses\n",
    "    c_loss = content_loss(stylized_content_feats[0], content_feats[0])\n",
    "    s_loss = style_loss(stylized_style_feats, style_feats)\n",
    "    tv_loss = total_variation_loss(stylized_image)\n",
    "    \n",
    "    # Total loss with explicit weighting\n",
    "    weighted_s_loss = style_weight * s_loss\n",
    "    loss = content_weight * c_loss + weighted_s_loss + tv_weight * tv_loss\n",
    "    \n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    # Recalculate losses for logging\n",
    "    with torch.no_grad():\n",
    "        stylized_image = model(content_tensor)\n",
    "        stylized_content_feats, stylized_style_feats = feature_extractor(stylized_image)\n",
    "        c_loss = content_loss(stylized_content_feats[0], content_feats[0])\n",
    "        s_loss = style_loss(stylized_style_feats, style_feats)\n",
    "        tv_loss = total_variation_loss(stylized_image)\n",
    "        weighted_s_loss = style_weight * s_loss\n",
    "        loss = content_weight * c_loss + weighted_s_loss + tv_weight * tv_loss\n",
    "    \n",
    "    # Save losses\n",
    "    content_losses.append(c_loss.item())\n",
    "    style_losses.append(s_loss.item())\n",
    "    tv_losses.append(tv_loss.item())\n",
    "    total_losses.append(loss.item())\n",
    "    \n",
    "    # Convergence check\n",
    "    if loss.item() < best_loss - min_loss_improvement:\n",
    "        best_loss = loss.item()\n",
    "        no_improvement_count = 0\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "    \n",
    "    # Print progress every 10 epochs\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
    "              f\"Content Loss: {c_loss.item():.4f} | Style Loss: {weighted_s_loss.item():.6f} | \"\n",
    "              f\"TV Loss: {tv_loss.item():.4f} | Total Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if no_improvement_count >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}: Loss improvement < {min_loss_improvement} for {patience} epochs\")\n",
    "        break\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), '/kaggle/working/starry_night_style_model.pth')\n",
    "\n",
    "# Save the final stylized image with color enhancement\n",
    "with torch.no_grad():\n",
    "    final_stylized = model(content_tensor)\n",
    "    final_stylized = final_stylized.squeeze(0).cpu()\n",
    "    final_stylized = (final_stylized + 1) / 2\n",
    "    final_stylized = final_stylized * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    final_stylized = final_stylized.clamp(0, 1)\n",
    "    output_image = transforms.ToPILImage()(final_stylized)\n",
    "    output_image = ImageEnhance.Color(output_image).enhance(1.5)\n",
    "    output_image.save('/kaggle/working/stylized_starry_night_output2.jpg')\n",
    "\n",
    "\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29e6bcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T11:19:33.849455Z",
     "iopub.status.busy": "2025-04-03T11:19:33.849215Z",
     "iopub.status.idle": "2025-04-03T11:19:34.701725Z",
     "shell.execute_reply": "2025-04-03T11:19:34.700857Z"
    },
    "papermill": {
     "duration": 0.901618,
     "end_time": "2025-04-03T11:19:34.703895",
     "exception": false,
     "start_time": "2025-04-03T11:19:33.802277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def moving_average(data, window_size=50):\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "window_size = 50\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(moving_average(content_losses, window_size), label='Content Loss (Smoothed)', color='blue')\n",
    "plt.title('Content Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(moving_average(style_losses, window_size), label='Style Loss (Smoothed)', color='green')\n",
    "plt.title('Style Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(moving_average(tv_losses, window_size), label='TV Loss (Smoothed)', color='orange')\n",
    "plt.title('Total Variation Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(moving_average(total_losses, window_size), label='Total Loss (Smoothed)', color='red')\n",
    "plt.title('Total Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7036213,
     "sourceId": 11258429,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22433.361991,
   "end_time": "2025-04-03T11:19:36.396383",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-03T05:05:43.034392",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
